# ğŸ”¹ Project Overview

PayMatch: Intelligent Userâ€“Transaction Mapping & Semantic Search
This project implements two main tasks:

1. **Task 1 â€” Match Users to Transactions**
   Given a transaction ID, return the most likely users who match the payment.

   * Hybrid approach: fuzzy matching, trigram index, embeddings, and description-to-user similarity.
   * Enhanced by an **LLM (OpenAI GPT)** for better name extraction from noisy descriptions.

2. **Task 2 â€” Semantic Transaction Search**
   Given a free-text query, return the most semantically similar transactions.

   * Uses **BM25** for fast candidate retrieval, **embeddings** for semantic similarity, and a **Qdrant vector DB** for large-scale ANN search.
   * Enhanced by an **LLM (OpenAI GPT)** for query expansion (improves recall) and reranking (improves precision).

---

## ğŸ”¹ Setup Instructions

### 1. Clone & install dependencies

```bash
git clone <repo_url>
cd project
python -m venv .venv
source .venv/bin/activate  # On Windows use: .venv\Scripts\activate
pip install -r requirements.txt
```

> ğŸ’¡ For a lightweight setup, you can install only `requirements-minimal.txt`:
>
> ```bash
> pip install -r requirements-minimal.txt
> ```

---

### 2. Add `.env` file

Create a file called **`.env`** in the project root (same level as `requirements.txt`):

```ini
# Required if you want LLM features
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_CHAT_MODEL=gpt-4o-mini

# Optional configs
QDRANT_HOST=localhost
QDRANT_PORT=6333
```

> ğŸ”’ **Do not commit `.env`** to git. Keep it local or use a secrets manager in production.

---

### 3. Run the server

Start the FastAPI app:

```bash
uvicorn main:app --reload --host 127.0.0.1 --port 8000
```

You can now access interactive API docs at:
ğŸ‘‰ [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)

---

## ğŸ”¹ Example Usage

### Task 1: Match Users to Transaction

**Request (with LLM parsing):**

```bash
curl "http://127.0.0.1:8000/match_transaction/caqjJtrI?top_k=5&min_score=30&use_llm_for_parse=true"
```

**Response:**

```json
{
  "users": [
    {"id": "U4NNQUQIeE", "match_metric": 89.25},
    {"id": "U7XJLPMqf1", "match_metric": 72.14}
  ],
  "total_number_of_matches": 2
}
```

* `use_llm_for_parse=true` â†’ Uses GPT to extract names from transaction description.
* If omitted, it falls back to heuristics.

---

### Task 2: Search Transactions

**Baseline search:**

```bash
curl "http://127.0.0.1:8000/search_transactions/?query=consulting%20fee&top_k=5"
```

**With LLM enhancements (expansion + rerank):**

```bash
curl "http://127.0.0.1:8000/search_transactions/?query=consulting%20fee&top_k=5&use_llm_for_expansion=true&use_llm_for_rerank=true"
```

**Response:**

```json
{
  "transactions": [
    {"id": "TXN123", "embedding": 0.8123},
    {"id": "TXN456", "embedding": 0.8011},
    {"id": "TXN789", "embedding": 0.7955}
  ],
  "total_number_of_tokens_used": 9
}
```

* `use_llm_for_expansion=true` â†’ GPT generates query paraphrases for better recall.
* `use_llm_for_rerank=true` â†’ GPT reranks the top candidates for better precision.

---

ğŸ”¹ Task Discussions
Task 1: Userâ€“Transaction Matching
Solution Approach:
	â€¢ Combines multiple signals to make the match robust:
		â—‹ Fuzzy Matching â†’ Handles typos and minor variations in names.
		â—‹ Trigram Index â†’ Speeds up approximate string comparisons.
		â—‹ Embeddings â†’ Captures semantic similarity between transaction descriptions and user names.
		â—‹ Description-to-User Similarity â†’ Embedding-based scoring of the transaction text against all user profiles.
	â€¢ LLM Enhancement: When enabled, GPT parses transaction descriptions to extract possible user names (e.g., from â€œPayment received from J. Doe for invoice #123â€).
Limitations:
	â€¢ Without LLM:
		â—‹ Nicknames and abbreviations may not match well (e.g., â€œJonâ€ vs â€œJonathanâ€).
		â—‹ Very noisy transaction descriptions can defeat fuzzy/embedding matching.
	â€¢ With LLM:
		â—‹ Latency: Adds ~200â€“1000ms due to API calls.
		â—‹ Cost: Increases per-request cost depending on token usage.
		â—‹ Non-determinism: Same query may yield slightly different parsing results.
	â€¢ Hybrid fallback ensures the system is never fully dependent on GPT, but reliability may still vary on edge cases.

Task 2: Semantic Transaction Search
Solution Approach:
	â€¢ BM25: Lexical search to retrieve top candidate transactions quickly.
	â€¢ Embeddings: Re-rank those candidates by semantic closeness.
	â€¢ Qdrant (optional): Enables large-scale Approximate Nearest Neighbor (ANN) search for efficiency.
	â€¢ LLM Enhancements:
		â—‹ Query Expansion â†’ GPT generates paraphrases (â€œconsulting feeâ€ â†’ â€œadvisory services paymentâ€), boosting recall.
		â—‹ Reranking â†’ GPT refines the ranking, improving precision for subtle matches.
Limitations:
	â€¢ Without LLM:
		â—‹ Misses queries phrased differently from transaction text (synonyms, paraphrases).
		â—‹ BM25 alone struggles with out-of-vocabulary words.
	â€¢ With LLM:
		â—‹ Latency + Cost: Multiple GPT calls (expansion + rerank) make it heavier than baseline search.
		â—‹ Non-determinism: Expanded queries may include irrelevant paraphrases.
		â—‹ Scaling: Running LLM-powered reranking on thousands of results can be expensive.
	â€¢ Production systems should use LLM selectively, cache expansions, and integrate observability for token usage.


ğŸ”¹ Task 3: Taking This Proof of Concept to Production
If given additional resources, hereâ€™s how this system could be hardened and scaled for real-world production use:
ğŸ”§ System Improvements
	â€¢ Scalability:
		â—‹ Move from BM25 + local embeddings to fully managed vector DB (Qdrant, Pinecone, Weaviate) for fast, distributed semantic search.
		â—‹ Introduce sharding & replication for handling millions of users and transactions.
	â€¢ LLM Usage Optimization:
		â—‹ Apply LLM selectively â€” only on low-confidence matches or ambiguous queries, reducing cost and latency.
		â—‹ Cache common query expansions and parsed transaction names to avoid repeated GPT calls.
		â—‹ Experiment with smaller local LLMs (e.g., Llama 3, Mistral) for cost control, while keeping GPT for high-value tasks.
	â€¢ Observability & Monitoring:
		â—‹ Integrate with Prometheus + Grafana to track:
			Â§ Matching accuracy (precision/recall)
			Â§ Token consumption and latency from LLM calls
			Â§ System throughput & error rates
		â—‹ Add tracing (OpenTelemetry) for request pipelines.
	â€¢ Robustness:
		â—‹ Train a supervised ML model on historical transactionâ€“user matches to replace or augment heuristics.
		â—‹ Add active learning loop: collect feedback when predictions are wrong and use it to retrain models.
		â—‹ Build a fallback strategy (e.g., embeddings-only) if LLM services are unavailable.
	â€¢ Deployment & Ops:
		â—‹ Containerize with Docker and orchestrate with Kubernetes for scaling across environments.
		â—‹ Use CI/CD pipelines (GitHub Actions, GitLab CI) to automate tests, builds, and deployments.
		â—‹ Secure credentials with Vault / AWS Secrets Manager instead of .env files.
	â€¢ Compliance & Security:
		â—‹ Encrypt sensitive transaction/user data at rest and in transit.
		â—‹ Ensure logs are sanitized (no PII leakage to LLM prompts).
		â—‹ Add audit logs for regulatory compliance (especially if used in finance).
ğŸš€ Roadmap for Production
	1. MVP (Current POC) â†’ FastAPI app with hybrid matching & search, optional GPT calls.
	2. Pilot Deployment â†’ Add Qdrant + monitoring, use LLM selectively with caching.
	3. Full Production â†’ ML-trained matcher, containerized deployment on Kubernetes, scalable vector DB, full observability, security hardening.


